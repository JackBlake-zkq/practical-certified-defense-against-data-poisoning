{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackBlake-zkq/robust-edge-inference/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fa_ensemble import FiniteAggregationEnsemble\n",
        "from torchvision.datasets import CIFAR10, MNIST\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import random\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "import ssl\n",
        "from models.resnet import ResNet18, ResNet18_1C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainset = CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([\n",
        "#     transforms.RandomCrop(32, padding=4),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "# ]))\n",
        "\n",
        "# testset = CIFAR10(root='./data', train=False, download=True, transform=transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "# ]))\n",
        "trainset = MNIST(root='./datasets/MNIST', train=True, download=True, transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "]))\n",
        "testset = MNIST(root='./datasets/MNIST', train=False, download=True, transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_base_model(partition_number, train_subset):\n",
        "    seed = partition_number\n",
        "    random.seed(seed)\n",
        "    numpy.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    curr_lr = 0.1\n",
        "    epochs = 5\n",
        "    device = (\n",
        "        \"cuda\"\n",
        "        if torch.cuda.is_available()\n",
        "        else \"mps\"\n",
        "        if torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        "    device += \":\" + str(partition_number)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=1)\n",
        "    print(\"subset has \", len(train_subset), \"data points\")\n",
        "    \n",
        "    ssl._create_default_https_context = ssl._create_unverified_context\n",
        "    net = ResNet18_1C() if isinstance(trainset, MNIST) else ResNet18()\n",
        "\n",
        "    net = net.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=curr_lr, momentum=0.9, weight_decay=0.0005, nesterov= True)\n",
        "\n",
        "    # Training\n",
        "    net.train()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for (inputs, targets) in trainloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if (epoch in [60,120,160]):\n",
        "            curr_lr = curr_lr * 0.2\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = curr_lr\n",
        "\n",
        "\n",
        "    net.eval()\n",
        "    nomtestloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=1)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for (inputs, targets) in nomtestloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "        break\n",
        "    acc = 100.*correct/total\n",
        "    print(f'Estimated accuracy for base model {partition_number}: {str(acc)}%')\n",
        "\n",
        "    return net\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base model 0 already exists\n",
            "Base model 1 already exists\n",
            "Base model 2 already exists\n",
            "Base model 3 already exists\n",
            "Base model 4 already exists\n",
            "Base model 5 already exists\n",
            "Base model 6 already exists\n",
            "Base model 7 already exists\n",
            "Base model 8 already exists\n",
            "Base model 9 already exists\n",
            "Base model 10 already exists\n",
            "Base model 11 already exists\n",
            "Base model 12 already exists\n",
            "Base model 13 already exists\n",
            "Base model 14 already exists\n",
            "Base model 15 already exists\n",
            "Base model 16 already exists\n",
            "Base model 17 already exists\n",
            "Base model 18 already exists\n",
            "Base model 19 already exists\n",
            "Base model 20 already exists\n",
            "Base model 21 already exists\n",
            "Base model 22 already exists\n",
            "Base model 23 already exists\n",
            "Base model 24 already exists\n",
            "Base model 25 already exists\n",
            "Base model 26 already exists\n",
            "Base model 27 already exists\n",
            "Base model 28 already exists\n",
            "Base model 29 already exists\n"
          ]
        }
      ],
      "source": [
        "# ensemble = FiniteAggregationEnsemble(trainset, testset, train_base_model, 10, k=50, d=3, channels=1, state_dir=\"mnist_k50_d3\")\n",
        "# for i in range(150):\n",
        "#     ensemble.train_base_model(i)\n",
        "ensemble = FiniteAggregationEnsemble(trainset, testset, train_base_model, 10, k=10, d=3, channels=1, state_dir=\"mnist_k10_d3\")\n",
        "for i in range(30):\n",
        "    ensemble.train_base_model(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testset predictions already computed, using those...\n",
            "Certificates already computed, using those...\n",
            "Base classifier accuracy: 89.65433333333333\n",
            "Median - Ensemble Accuracy: 98.36%\n",
            "Median - Certified Radius: 1.0\n"
          ]
        }
      ],
      "source": [
        "ensemble.eval(mode=\"logit_median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainset predictions already computed, using those...\n",
            "Computing ensemble output on trainset...\n",
            "Student already trained\n",
            "Evaluating Student\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jackblake/Documents/UW_Courswork/robust-edge-inference/fa_ensemble.py:317: UserWarning: torch.sort is supported by MPS on MacOS 13+, please upgrade. Falling back to CPU (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Sort.mm:45.)\n",
            "  logits, _ = alt.to(device).sort(dim=2)\n",
            "100%|██████████| 79/79 [00:08<00:00,  9.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for student: 95.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "student = ResNet18_1C() if isinstance(trainset, MNIST) else ResNet18()\n",
        "ensemble.distill(student, mode='logit_median', lr=0.0001)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
