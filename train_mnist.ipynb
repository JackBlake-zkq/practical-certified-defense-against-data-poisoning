{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackBlake-zkq/robust-edge-inference/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fa_ensemble import FiniteAggregationEnsemble\n",
        "from torchvision.datasets import CIFAR10, MNIST\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import random\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "import ssl\n",
        "from models.resnet import ResNet18, ResNet18_1C, ResNetSmall_1C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainset = MNIST(root='./datasets/MNIST', train=True, download=True, transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "]))\n",
        "testset = MNIST(root='./datasets/MNIST', train=False, download=True, transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_base_model(partition_number, train_subset):\n",
        "    seed = partition_number\n",
        "    random.seed(seed)\n",
        "    numpy.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    curr_lr = 0.01\n",
        "    epochs = 10\n",
        "    device = (\n",
        "        \"cuda\"\n",
        "        if torch.cuda.is_available()\n",
        "        else \"mps\"\n",
        "        if torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        "    device += \":\" + str(partition_number)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=1)\n",
        "    print(\"subset has \", len(train_subset), \"data points\")\n",
        "    \n",
        "    ssl._create_default_https_context = ssl._create_unverified_context\n",
        "    net = ResNet18_1C()\n",
        "\n",
        "    net = net.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=curr_lr, momentum=0.9, weight_decay=0.0005, nesterov= True)\n",
        "\n",
        "    # Training\n",
        "    net.train()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for (inputs, targets) in trainloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if (epoch in [60,120,160]):\n",
        "            curr_lr = curr_lr * 0.2\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = curr_lr\n",
        "\n",
        "\n",
        "    net.eval()\n",
        "    nomtestloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=1)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for (inputs, targets) in nomtestloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "        break\n",
        "    acc = 100.*correct/total\n",
        "    print(f'Estimated accuracy for base model {partition_number}: {str(acc)}%')\n",
        "\n",
        "    return net\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base model 0 already exists\n",
            "Base model 1 already exists\n",
            "Base model 2 already exists\n",
            "Base model 3 already exists\n",
            "Base model 4 already exists\n",
            "Base model 5 already exists\n",
            "Base model 6 already exists\n",
            "Base model 7 already exists\n",
            "Base model 8 already exists\n",
            "Base model 9 already exists\n",
            "Base model 10 already exists\n",
            "Base model 11 already exists\n",
            "Base model 12 already exists\n",
            "Base model 13 already exists\n",
            "Base model 14 already exists\n",
            "Base model 15 already exists\n",
            "Base model 16 already exists\n",
            "Base model 17 already exists\n",
            "Base model 18 already exists\n",
            "Base model 19 already exists\n",
            "Base model 20 already exists\n",
            "Base model 21 already exists\n",
            "Base model 22 already exists\n",
            "Base model 23 already exists\n",
            "Base model 24 already exists\n",
            "Base model 25 already exists\n",
            "Base model 26 already exists\n",
            "Base model 27 already exists\n",
            "Base model 28 already exists\n",
            "Base model 29 already exists\n"
          ]
        }
      ],
      "source": [
        "ensemble = FiniteAggregationEnsemble(\"ensembles/mnist_k30_d1\", trainset, testset, 10, 30)\n",
        "for i in range(30):\n",
        "    ensemble.train_base_model(i, train_base_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testset predictions already computed, using those...\n",
            "Certificates already computed, using those...\n",
            "Base classifier accuracy: 97.14733333333334\n",
            "Clean Accuracy: 98.07000000000001%\n",
            "Median Certified Radius: 15\n"
          ]
        }
      ],
      "source": [
        "ensemble.eval(\"softmax_median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testset predictions already computed, using those...\n",
            "Certificates already computed, using those...\n",
            "Base classifier accuracy: 97.14733333333334\n",
            "Clean Accuracy: 98.11999999999999%\n",
            "Median Certified Radius: 15\n"
          ]
        }
      ],
      "source": [
        "ensemble.eval(\"logit_median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testset predictions already computed, using those...\n",
            "Certificates already computed, using those...\n",
            "Base classifier accuracy: 97.14733333333334\n",
            "Clean Accuracy: 98.06%\n",
            "Median Certified Radius: 15\n"
          ]
        }
      ],
      "source": [
        "ensemble.eval(mode=\"label_voting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testset predictions already computed, using those...\n",
            "Certificates already computed, using those...\n",
            "Base classifier accuracy: 97.14733333333334\n",
            "Clean Accuracy: 98.00999999999999%\n",
            "Median Certified Radius: 15\n"
          ]
        }
      ],
      "source": [
        "ensemble.eval(mode=\"label_runoff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ensembles/mnist_k30_d1/students/student_softmax_median11529215046068470450.pkl\n",
            "Student already trained with those parameters at ensembles/mnist_k30_d1/students/student_softmax_median11529215046068470450.pkl, loading it in instead of training again...\n",
            "Evaluating Student\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:05<00:00, 14.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for student: 98.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ensemble.distill(ResNetSmall_1C(), 'softmax_median', lr=0.05, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ensembles/mnist_k30_d1/students/student_logit_median230584300921369450.pkl\n",
            "Student already trained with those parameters at ensembles/mnist_k30_d1/students/student_logit_median230584300921369450.pkl, loading it in instead of training again...\n",
            "Evaluating Student\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:05<00:00, 15.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for student: 97.92%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ensemble.distill(ResNetSmall_1C(), mode='logit_median', lr=1e-3, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ensembles/mnist_k30_d1/students/student_label_voting230584300921369450.pkl\n",
            "Student already trained with those parameters at ensembles/mnist_k30_d1/students/student_label_voting230584300921369450.pkl, loading it in instead of training again...\n",
            "Evaluating Student\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:05<00:00, 15.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for student: 98.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ensemble.distill(ResNetSmall_1C(), 'label_voting', lr=1e-3, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9651"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble.certified_accuracy(\"softmax_median\", 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9232"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble.certified_accuracy(\"softmax_median\", 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble.certified_accuracy(\"softmax_median\", 20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
